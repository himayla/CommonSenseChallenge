{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dir = \"common-sense\"\n",
    "\n",
    "train_file = os.path.join(dir, \"train_data.csv\")\n",
    "train_labels_file = os.path.join(dir, \"train_answers.csv\")\n",
    "\n",
    "df_sentences = pd.read_csv(train_file)\n",
    "df_labels = pd.read_csv(train_labels_file)\n",
    "\n",
    "test_file = os.path.join(dir, \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    \"\"\"Convert options to (integer) labels\"\"\"\n",
    "    if x == 'A':\n",
    "        return 0\n",
    "    elif x == 'B':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df_labels['label'] = df_labels['answer'].apply(label)\n",
    "df_sentences = df_sentences.rename(columns={\"FalseSent\": \"sent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I sting a mosquito</td>\n",
       "      <td>A human is a mammal</td>\n",
       "      <td>A human is omnivorous</td>\n",
       "      <td>A human has not stings</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A giraffe is a person.</td>\n",
       "      <td>Giraffes can drink water from a lake.</td>\n",
       "      <td>A giraffe is not a human being.</td>\n",
       "      <td>.Giraffes usually eat leaves.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A normal closet is larger than a walk-in closet.</td>\n",
       "      <td>Walk-in closets are normal closets.</td>\n",
       "      <td>A person can sleep in a walk-in closet.</td>\n",
       "      <td>A person cannot walk into a normal closet beca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I like to ride my chocolate</td>\n",
       "      <td>Chocolate is delicious and bikes are not</td>\n",
       "      <td>Chocolate is a food, not a transportation unit</td>\n",
       "      <td>My bike can't ride a chocolate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A GIRL WON THE RACE WITH HORSE</td>\n",
       "      <td>GIRL HAVE BEAUTIFUL HAIR BUT THE HORSE DOESN'T...</td>\n",
       "      <td>THE GIRL WEAR DRESS BUT THE HORSE DOESN'T HAVE .</td>\n",
       "      <td>HORSE RAN FASTER THAN HER</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent  \\\n",
       "0                                I sting a mosquito   \n",
       "1                            A giraffe is a person.   \n",
       "2  A normal closet is larger than a walk-in closet.   \n",
       "3                       I like to ride my chocolate   \n",
       "4                    A GIRL WON THE RACE WITH HORSE   \n",
       "\n",
       "                                             OptionA  \\\n",
       "0                                A human is a mammal   \n",
       "1              Giraffes can drink water from a lake.   \n",
       "2                Walk-in closets are normal closets.   \n",
       "3           Chocolate is delicious and bikes are not   \n",
       "4  GIRL HAVE BEAUTIFUL HAIR BUT THE HORSE DOESN'T...   \n",
       "\n",
       "                                            OptionB  \\\n",
       "0                             A human is omnivorous   \n",
       "1                   A giraffe is not a human being.   \n",
       "2           A person can sleep in a walk-in closet.   \n",
       "3    Chocolate is a food, not a transportation unit   \n",
       "4  THE GIRL WEAR DRESS BUT THE HORSE DOESN'T HAVE .   \n",
       "\n",
       "                                             OptionC  label  \n",
       "0                             A human has not stings      2  \n",
       "1                      .Giraffes usually eat leaves.      1  \n",
       "2  A person cannot walk into a normal closet beca...      2  \n",
       "3                     My bike can't ride a chocolate      1  \n",
       "4                          HORSE RAN FASTER THAN HER      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine sentences and labels dataframes\n",
    "df = pd.merge(df_sentences, df_labels, on=\"id\").drop([\"id\", \"answer\"], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer 0/A</th>\n",
       "      <th>Answer 1/B</th>\n",
       "      <th>Answer 2/C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_answers</th>\n",
       "      <td>2597</td>\n",
       "      <td>2665</td>\n",
       "      <td>2738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Answer 0/A  Answer 1/B  Answer 2/C\n",
       "n_answers        2597        2665        2738"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory\n",
    "n_0 = len(df.loc[df['label'] == 0])\n",
    "n_1 = len(df.loc[df['label'] == 1])\n",
    "n_2 = len(df.loc[df['label'] == 2])\n",
    "\n",
    "pd.DataFrame([[n_0, n_1, n_2]], columns=['Answer 0/A','Answer 1/B','Answer 2/C'], index=[\"n_answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# from transformers import BertTokenizer # Alternative\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "def preprocess(text: str) -> list:\n",
    "    \"\"\"Remove punctuation, remove stopwords, tokenize words\"\"\"\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)   \n",
    "\n",
    "    tokens = [x.lower() for x in tokens if not x in set(stopwords.words('english'))] \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the rest of the notebook is just simply classifying sent (X) to label (Y). The options are not taken into account yet.\n",
    "Based on tutorial from: https://medium.com/mlearning-ai/convert-texts-into-tensors-for-deep-learning-74b0cf48d416 and https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-simple-guide-to-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data: list[str]) -> dict:\n",
    "    \"\"\"Map term to index\"\"\"\n",
    "    vocab = {'pad': 0, '</e>': 1, '<unk>': 2} \n",
    "\n",
    "    for row in data: \n",
    "        processed_text = preprocess(row)\n",
    "        for word in processed_text:\n",
    "            if word not in vocab:\n",
    "                # Create entry in the vocab equal to the term, and its value is the length of the vocab \n",
    "                vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(df[\"sent\"].values) # Should maybe be build with options not sent???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I sting a mosquito', 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(zip(df['sent'].values, df['label'].values)) \n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Split the dataset\n",
    "lengths = [int(len(dataset) * 0.8), int(len(dataset) * 0.2)]\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    X, y = list(zip(*batch))\n",
    "    X = vectorizer.transform(X).todense()\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256, collate_fn=vectorize_batch)\n",
    "test_loader = DataLoader(val_set, batch_size=256, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 6277]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(len(vocab), 128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        return self.seq(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3])\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier()\n",
    "\n",
    "for X, y in train_loader:\n",
    "    y_preds = model(X)\n",
    "    print(y_preds.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        y_shuffled, y_preds, losses = [],[],[]\n",
    "        for X, y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            y_shuffled.append(y)\n",
    "            y_preds.append(preds.argmax(dim=-1))\n",
    "\n",
    "        y_shuffled = torch.cat(y_shuffled)\n",
    "        y_preds = torch.cat(y_preds)\n",
    "\n",
    "        print(\"Valid Loss: {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        print(\"Valid Accuracy: {:.3f}\".format(accuracy_score(y_shuffled.detach().numpy(), y_preds.detach().numpy())))\n",
    "\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, y in tqdm(train_loader):\n",
    "            y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(y_preds, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        CalcValLossAndAccuracy(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.099\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.098\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.097\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 49.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.096\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 26.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.093\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.090\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.085\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.078\n",
      "Valid Loss: 1.099\n",
      "Valid Accuracy: 0.346\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "epochs = 8\n",
    "learning_rate = 1e-4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "text_classifier = TextClassifier()\n",
    "optimizer = Adam(text_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(text_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePredictions(model, loader):\n",
    "    y_shuffled, y_preds = [], []\n",
    "    for X, y in loader:\n",
    "        preds = model(X)\n",
    "        y_preds.append(preds)\n",
    "        y_shuffled.append(y)\n",
    "    gc.collect()\n",
    "    y_preds, y_shuffled = torch.cat(y_preds), torch.cat(y_shuffled)\n",
    "\n",
    "    return y_shuffled.detach().numpy(), F.softmax(y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n",
    "\n",
    "y_actual, y_preds = MakePredictions(text_classifier, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.345625\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     OptionA       0.34      0.42      0.37       516\n",
      "     OptionB       0.33      0.08      0.13       538\n",
      "     OptionC       0.35      0.53      0.43       546\n",
      "\n",
      "    accuracy                           0.35      1600\n",
      "   macro avg       0.34      0.35      0.31      1600\n",
      "weighted avg       0.34      0.35      0.31      1600\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "[[217  47 252]\n",
      " [216  45 277]\n",
      " [211  44 291]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(y_actual, y_preds)))\n",
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(y_actual, y_preds, target_names=['OptionA', 'OptionB', 'OptionC']))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(y_actual, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff I tried for the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_options = []\n",
    "# for option in list(zip(df['OptionA'], df['OptionB'], df['OptionB'])):\n",
    "#     a = text_to_tensor(option[0], vocab)\n",
    "#     b = text_to_tensor(option[1], vocab)\n",
    "#     c = text_to_tensor(option[2], vocab)\n",
    "\n",
    "#     all_options.append((a, b, c))\n",
    "\n",
    "# all_options[1] # Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# ids = torch.tensor(df.index)\n",
    "# options = torch.tensor(all_options)\n",
    "# labels = torch.tensor(df.label)\n",
    "\n",
    "# train = TensorDataset(ids, options, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answers: A, B, C -> Features\n",
    "# TODO: Sentences: OptionA, OptionB, OptionC -> Features\n",
    "\n",
    "# from transformers import BertTokenizer\n",
    "# import itertools\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# features = {}\n",
    "\n",
    "# # Convert to tokens !!(Now set on 500)\n",
    "# for sent_idx, sentence in df[:500].iterrows():\n",
    "#     sent_tokens = tokenizer.tokenize(sentence['sent'])\n",
    "\n",
    "#     option_a = tokenizer.tokenize(sentence[0])\n",
    "#     option_b = tokenizer.tokenize(sentence[1])\n",
    "#     option_c = tokenizer.tokenize(sentence[2])\n",
    "\n",
    "#     options = list(itertools.chain(option_a, option_b, option_c))\n",
    "\n",
    "#     features[sent_idx] = {\n",
    "#         \"Sentence\": sent_tokens,\n",
    "#         \"Options\": options,\n",
    "#         \"Label\": sentence.label\n",
    "#     }\n",
    "\n",
    "# print(features[5]) # Just for testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
